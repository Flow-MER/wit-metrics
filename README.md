# WIT-metrics

Jupyter notebook

Calculate inundation summary metrics from Geoscience Austarlia Wetland Insights Tool (WIT) data (csv files)

https://knowledge.dea.ga.gov.au/data/product/dea-wetlands-insight-tool-ramsar-wetlands/

Dunn et al paper:  https://link.springer.com/article/10.1007/s13157-023-01682-7

## Lineage

This notebook was derived from some initial code Geosciences Australia contributed to an MDBA project BWS Vulnerabilities"
Changes since include:
* batch input of multiple WIT CVS in a folder (currently the ANAEv3 WIT output includes 270,653 polygons, each with its own csv file)
* multiple processor pool support to speed execution when running on a PC workstation
* linear interpolation of the observations dates to daily data to improve estimates of inundation duration
* some bug fixes in the inundation event metrics that were required when using the interpolated data
* output formatting

## Dependencies
     * A folder containing WIT csv (obtained for the BWS Priorities Project from Geosciences Australia for each ANAE polygon > 1Ha)
     * A shapefile (or equivalent) that contains the area that the WIT result was run over.
  
     
## Background
The WIT data are generated by DEA with given wetland polygons and stored in a database on NCI. The data can be dumped into a csv when required. Any statistics can be generated with WIT data. This notebook provides a way in computing temporal statistics (metrics).

## WIT Data definition
* WIT data provides the following metrics for each polygon unit

```
   date: time of observation
   bs: percentage of bare soil
   npv: percentage of non photosynthetic vegetation
   pv: percentage of green/photosynthetic vegetation
   wet: percentage of wetness
   water: percentage of water
```

## Description
This notebook uses existing WIT data to compute metrics.
* First we load the existing WIT csv data from a saved csv location
* Then we compute the metrics for all polygons and output the results to CSV files.  The input CSV files are processed in "batches" that are spread across multiple CPU cores.  When execution is complete the various batch outputs are merged together into single result files that contain metrics for every CSV feature ID (e.g. ANAE polygons)

The following files are created:

 - **RESULT_WIT_yearly_metrics**: min, max, mean, median of each WIT metric per calendar year
 - **RESULT_WIT_event_threshold**: for the BWS project we defined an "event" as exceeding the median [water+wet] - this file is read in to calculate the event metrics but could be replaced with user selected values if custom thresholds were wanted or the routine that generates it could be altered to change the threshold formulaiclly.
 - **RESULT_WIT_time_since_last_inundation**: number of days since the inundation event threshold was exceeded
 - **RESULT_WIT_event_times**: start and end time, duration, duration of preceeding gap (the dry period) 
 - **RESULT_WIT_event_stats**: for each event calculates the area of the polygon that was wet using the combination water+wet
 - **RESULT_WIT_inundation_metrics**: this is a join of the RESULT_WIT_ANAE_event_time and RESULT_WIT_ANAE_event_stats

## Processing Environment
For the MDBA BWS Vulnerabilities project the notebook was run in the python processing environment of ArcGIS Pro 3.0 but it was designed to use common open source python data processing libraries (Geopandas, Pandas, numpy) that should enable the analysis to be repeated in most environments.

***
     
# Lead
- Dr Shane Brooks
